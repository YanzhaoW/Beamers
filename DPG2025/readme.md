
## script

### Slide 1

Hello, everyone. For the next 12 mins, I would like to show you an overview of data calibration algorithms we use for NeuLAND in the R3B setup.

### Slide 2

First, let me shortly talk about the R3B. The R3B setup, as a part of FAIR project in GSI, is utilizing high energetic radioactive beam on the target surrounded by the proton and photon detector. Behind the target, we have strong magnetic field, which makes sure our neutron detector, NeuLAND, only receives chargeless particles, such like neutrons protons. 

Currently Neuland has 26 planes. For every two planes, the first one is made of 50 scintillator bars placed horizontally and the second has the same amount of bars but placed vertically. Each bar is attached to two PMTs on both ends and thus we have 2600 PMTs in total in this huge detector.

With this large amount of scintillators and PMTs, the goal of NeuLAND is to measure the positions, times and energy depositions of the interactions of traveling particles inside the detector. The calibration process I'm going to introduce now is the way how we calculate those physical values from the binary data that we store during the beam time.

### Slide 3

But before we talk about the calibration, we have to discuss how the data was digitized at the first place. This is because most of time calibration can be more or less viewed as in inverse process of the digitization. So, first we have the particle interaction with the scintillator, which is represented by three physical data: energy, time and position. Then, PMT signals are generated and reshaped by a front-end charge integrator, FQT, which results in logic signals with leading edge and trailing edge. The width of the logical signal is corresponding to the energy deposition of the initial interaction. Then the TAMEX card measure the times of these two edges and store the data in form of TDC channel numbers and module IDs. After the beam time, we need to convert those TDC values back to the real physical data through two different stages of calibrations.

### Slide 4

The first calibration is about converting the TDC values to the real time values of logic signals. But to understand the process of this calibration, we need to know how we use TAMEX to measure the time of a signal. The time measurement contains two different systems. First, we have the coarse time system, which simply contains a clock signal with 200 MHz with the time resolution equal to 5ns. Of course, 5ns time resolution is too large. For this reason, we have another system called fine time system, which measures the fine time value within the 5ns. In principle, it's composed of a large number of comparators implemented in a FPGA and its output value, the fine time channel number, represents how many comparators the signal goes through. The TDC calibration is to find out the relation between the real fine times and its corresponding channel numbers.

This calibration is actually quite simple. With an assumption that the real fine time values are uniformly distributed within this 5ns and using a simple mathematical derivation, the calibration relation is simply just cumulative distribution function, or CDF, of the distribution of the fine time channel numbers. And with this, we can convert all TDC values to the real time values of the logic signals. But having real time values is not enough. We still need the second stage of the calibration that converts those time values to the physical data, such as interaction time, position and energy depositions.

### Slide 5

For this, the position of the interaction can be described with the time difference of two PMT signals on the same bar, while the interaction time is related to the their summation. The first parameter, with the symbol Ce here, is the effective speed of light, which represents both the traveling speed of the photon and the light reflection inside the scintillator. The other two time related parameters comes from the different lengths of cables connecting not only to different scintillators and but also to two adjacent PMTs of the same bar. Due to the time issue, here I'm only talking about the steps for the position calibration. The first step is to collect time difference values of the two adjacent PMT signals from cosmic muons. And if we assume that cosmic muons hit the scintillator uniformly across the its whole length, we should expect a uniform distribution on the time difference like what we see in the picture on the top right. And from the first equation, we could easily know that width of this distribution should be related to the effective speed of light and center position related to the t offset parameter. Well, there are many ways to determine these two values from a uniform distribution. 

But what we do is simply convert the distribution to its CDF and do a linear fitting at a certain range. In the end, from the fitting algorithm, we can determine both values and errors of effective speed of light and t offset parameter.

### Slide 6

Similarly, the relation between the logic signal width to the energy deposition can be described by these 3 equations, which contains various energy related parameters, including width baseline parameter, energy gain of the PMT, the saturation parameter of the PMT and the light attenuation factor of the scintillator. Like what we do in the position calibration, energy calibration is also utilizing the signals from cosmic muons. But in contrast, it not only requires the full reconstruction of every muon track, but also relies on three difference assumptions: First the PMT saturation factor should be proportional to its gain factor. Second, the stopping power of the cosmic muons is 1.73 MeV/cm. In addition, the two adjacent PMTs must have same gain factor. With these assumptions and the equations above, the first parameter we could easily determine is the baseline parameter, as it's simply the minimum cut on the signal widths. Next, with the help of the position values from the reconstructed muon track, the attenuation factor can be calculated from the ratio of the signal width of the two adjacent PMTs. After the attenuation factor is known, with the muons' stopping power, we could further calculate the gain factor of all events, which is shown in the picture on the bottom right. Before I go to the last part of this talk, I have to mention that our calibration methods are not perfect and may have some inaccuracies. For example, in the position calibration, if we have a very low the statistics, the fitting process would lead to a really bad result. And same goes for the energy calibration if the reconstruction of the muon track is not precise or one the assumptions doesn't hold in the real situation.

### Slide 7

To solve this issue, we need an additional process of parameter fine tuning, which is based on the Millepede algorithm. The Millepede algorithm was first developed 20 years old at DESY for the alignment of tracking detectors and later used for other detectors, like LHC or CBM in GSI. But the underlying mathematics actually allows this algorithm to be used for the calibration of any type of detectors as long as particle tracks are utilized in the calibration, no matter whether we are dealing with scintillator, fiber or silicon detectors. The main characteristics of this algorithm is that first it's simultaneous fitting of all parameters including those belong to the individual particle track. It also has a separation to so-called global and local parameters. Third, the computation complexity is independent of local parameter size. What's most important is it doesn't require the reconstruction of each particle track. But unfortunately it does have a limitation that the calibration relation must be linear, which can be mitigated by taylor expending the relations around some decent initial values. So far we have used the millepede algorithms on improving the accuracy of the position calibration parameters. 

To prove this works, we also use the simulated data, which is generated according to some predefined parameter values, on the position calibration method and see whether the calibration could reproduce the predefined values. Here in this picture, we could see the predefined true values as a cosine function of the bar number. We could also see clearly from the green line that the results from the position calibration doesn't match really well with the predefined value. But using the Millepede algorithm as the parameter fine tuning, we achieved a much better result as we can see from the red line in the picture.
