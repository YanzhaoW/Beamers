
## script

### Slide 1

Hello, everyone. For the next 12 mins, I would like to introduce to you an overview of data calibration algorithms we use for NeuLAND in the R3B setup.

### Slide 2

The R3B setup, as a part of FAIR project in GSI, is utilizing high energetic radioactive beam on the target surrounded by the proton and photon detector. Behind the target, we have strong magnetic field, which makes sure our neutron detector, NeuLAND, only receives chargeless particles, such like neutrons. Currently Neuland has 26 planes. For every two planes, the first one is made of 50 scintillators placed horizontally and the second has the same amount of scintillators but placed vertically. Each plane is attached to two PMTs on both ends and thus we have 2600 PMTs in total in this huge detector. With this large amount of scintillators and PMTs, the goal of NeuLAND is to measure the positions, times and energy depositions of the interactions of traveling particles inside the detector. The calibration process I'm going to introduce now is the way how we calculate those physical values from the binary data that we store during the beam time.

### Slide 3

But before we talk about the calibration, we have to discuss how the data was digitized at the first place. This is because most of time calibration can be more or less viewed as in inverse process of the digitization. So, first we have the particle interaction with the scintillator, which is represented by three physical data: energy, time and position. Then, PMT signals are generated and reshaped by a front-end charge integrator, FQT, which results in a logic signal with leading edge and trailing edge. The width of the logical signal is corresponding to the energy deposition of the initial interaction. Then the TAMEX card measure the times of these two edges and store the data in form of TDC channel numbers and module IDs. After the beam time, we need to convert the TDC values back to the real physical data through two difference stages of calibrations.

### Slide 4

The first calibration is about converting the TDC values to the real time values of logic signals. But to understand the process of this calibration, we need to know how we use TAMEX to measure the time of a signal. The time measurement contains two different systems, coarse time system and fine time system. The coarse time system simply contains a clock signal with 200 MHz with the time resolution to be 5ns. Of course, 5ns time resolution is too large. For this reason, we have another system called fine time system, which measures the fine time value within the 5ns. In principle, it's composed of a large number of comparators implemented in a FPGA and its output value, the fine time channel number, represents how many comparators the signal goes through. The TDC calibration is to find out the relation between the real fine times and its corresponding channel numbers. This calibration is actually quite simple. With an assumption that the real fine time values are uniformly distribution with this 5ns and a mathematical derivation, the calibration relation is simply just cumulative distribution function, or CDF, of the distribution of the fine time channel numbers. And with this, we can convert all TDC values to the real time values of the logic signals. But having real time values is not enough. We still need the second stage of the calibration that converts those time values to the physical data, such as interaction time, position and energy depositions.

### Slide 5

The position of the interaction can be described with the time difference of two PMT signals on the same, while the interaction time is related to the time summation of the two PMT signals. The first parameter Ce is the effective speed of light, which represents both the traveling speed of the photon and the light reflection in the scintillator. The other two time related parameters comes from the difference lengths of cables connecting not only to different scintillators and but also to two PMTs of the same scintillator. Due to the time issue, here I'm only talking about the steps for the position calibration. The first step is to collect time difference values from the two PMTs on the same scintillator. Assuming that cosmic muons hit the scintillator uniformly across the its whole length, we should expect a uniform distribution on the time difference like what we see in the picture on the top right. And from the first equation, we also know the width of the distribution is related to the effective speed of light and center position related to the t offset parameter. Well, there are many ways to determine these two values from a uniform distribution. But what we do is simply convert it to its CDF and do a linear fitting at a certain range. In the end, from the fitting algorithm, we can determine the value and error of effective speed of light and t offset parameter.

### Slide 6

Similarly, the relation between the logic signal width, which is the time difference between the leading and trailing edge, and energy deposition can be described by these 3 equations, which contains various energy related parameters, including width baseline parameter, energy gain of the PMT, the saturation parameter of the PMT and the light attenuation factor of the scintillator. Like in the position calibration, energy calibration is also utilizing the signals from cosmic muons. But in contrast, it not only requires the full reconstruction of every muon track, but also relies on three difference assumptions: First the PMT saturation factor is proportional to its gain factor. Second, the stopping power of the cosmic muons is 1.73 MeV/cm. In addition, the two adjacent PMTs must have same gain factor. With these assumptions and the equations above, the first parameter we could easily determine is the baseline parameter, as it's simply the minimum cut on the signal widths. Next, with the help of the position values from the muon track reconstruction, the attenuation factor can be calculated as the ratio of the signal width of the two adjacent PMTs. After the attenuation factor is known, with the muons' stopping power, we could further calculate the gain factor of all events, which is shown in the picture on the bottom right. 

Before I go to the last part of this talk, I have to mention that our calibration methods are not perfect and may have some inaccuracies. For example, in the position calibration, if we have a very low the statistics, the fitting process would lead to a really bad result. And if the reconstruction of the muon track is not precise or one the assumptions don't hold in the real situation, the energy calibration could have lots of inaccuracies.

### Slide 7

To solve this issue, we need an additional process of parameter fine tuning, which is based on the Millepede algorithm. The Millepede algorithm was first developed 20 years old at DESY for the alignment of tracking detectors and later used for other detectors, like LHC or CBM in GSI. But the underlying mathematics actually allows this algorithm to be used for the calibration of any type of detectors, no matter whether it's a scintillator or silicon detector, as long as particle tracks are utilized in the calibration. The main characteristics of this algorithm is that first it's simultaneous fitting of all parameters including those belong to the individual particle track. It also has a separation to so-called global and local parameters. Third, the computation complexity is independent of local parameter size. What's most important is it doesn't require the reconstruction of each particle track. But unfortunately it does have a limitation that the calibration relation must be linear, which can be mitigated by taylor expending the relations around some decent initial values. So far we have used the millepede algorithms on improving the accuracy of the position calibration parameters. To prove this works, we also use the simulated data, which is generated according to predefined parameters, on the position calibration method and see whether the calibration could reproduce the predefined values. Here in this picture, you could see the predefined true values as a cosine function of the bar number. The results from the position calibration doesn't match really well with the predefined value. But using the Millepede algorithm as the parameter fine tuning, we achieved a much better result as we can see from the red lines here.
